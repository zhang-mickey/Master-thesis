# Mitigating Spurious Correlations in Weakly Supervised Semantic Segmentation via Cross-Model Consistency Regularization
<img width="1282" height="493" alt="image" src="https://github.com/user-attachments/assets/357db8b3-3b81-4bb7-ac8e-5c4274c5d3b5" />

# Effectiveness
<img width="735" alt="image" src="https://github.com/user-attachments/assets/133ba577-9516-42c7-91a7-75ae2911def0" />


# Paper 
```
https://doi.org/10.48550/arXiv.2507.21959
```


**Motivation**

CNN-based:better location 

Transformer-based :more clear boundary

![image](https://github.com/user-attachments/assets/cab5c84e-fb4d-4c7e-899f-f4051c069b30)

ResNet-based architecture as the teacher

Transformer-based architecture as the student model


# Methodology

## Cross-Architecture Feature Alignment Strategies

| Shape               | Keeps Channel Info? | Keeps Spatial Info? | Semantically Rich? |
|---------------------|---------------------|---------------------|--------------------|
| `[B, C × H × W]`    | ✅ Yes              | ✅ Yes              | ✅ Yes             |
| `[B, H × W]`        | ❌ No               | ✅ Yes              | ❌ No              |
| `[B, C, C]`         | ✅ Yes              | ❌ No               | ❌ No              |

choose B, C × H × W]

then feature projection layer


# Master-thesis

Pytorch implementation for Industrial exhaust smoke emission semantic segmentation using image level annotations.

Run on SURF

Industrial Exhaust Smoke emission-Oriented Pseudo label Refinement Method

## Background

Scarcity of pixel-level annotations.


![image](https://github.com/user-attachments/assets/97dfb59d-7e37-4cb6-b20d-0e9dd99ec332)


Sparse object coverage

over smoothing 

shortcut learning

inaccurate boundries

spurious corelations

## Observation and Motivation 


# Preparations

## Dataset description
The dataset is captured in specific locations, resulting in low variability in background contexts

**Train**

the introduction of our dataset(https://ijmondcam.multix.io/)

IJmond video frames(https://github.com/MultiX-Amsterdam/ijmond-camera-ai/tree/main/).

(https://github.com/MultiX-Amsterdam/ijmond-camera-monitor/tree/main/dataset/2024-01-22)

2488 Image size:[900,900]

Labeled as Smoke(1556) vs non-Smoke(932) to train a classifier.

**Test**


900 pixel-level labeled images of [1920,1280]. Instead of resize, crop the images to generate 2180 iamges of size [512,512]

Part of the following images served as out of distribution data

**Smoke 5K**
https://github.com/MultiX-Amsterdam/ijmond-camera-ai/tree/main/bvm_training/trans_bvm

**deep-smoke-machine**
https://github.com/CMU-CREATE-Lab/deep-smoke-machine

##  Preparing pretrained model

ViT-s and Vit-b

```
    'vit_small_patch16_224': _cfg(
        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/vit_small_p16_224-15ec54c9.pth',
    ),
    'vit_base_patch16_224': _cfg(
        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth',
        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),
    ),
```

Download the default SAM model checkpoint

```
sam_checkpoint=pretrained/sam_vit_h_4b8939.pth
```

## Prerequisite
The implementation of DenseCRF loss depends on fast bilateral filtering, which is provided in C++. Use SWIG to wrap C++ for python and then build the python module of bilateral filtering.
```
cd wrapper
swig -python -c++ bilateralfilter.i
python setup.py install
```

# Usage

#### 1. Train a classification network to get CAMs
To start training,just run the scripts `training/jobs/`.
```
sbatch training/jobs/kd.job
```
#### 2. Refinement


**Teacher Student Knowledge transfer** run the scripts `training/jobs/`

```
sbatch kd.job
```

**Teacher Student Knowledge transfer** run the scripts `training/jobs/`

```
sbatch co-teaching.job
```

#### post-processing
**AffinityNet**   run the scripts `post_processing/jobs/`
```
sbatch train_affinityNet.job

sbatch infer_affinityNet.job
```

**3. Evaluate**




## multi-stage Weakly supervised learning 
![image](https://github.com/user-attachments/assets/d566e36b-8010-4805-a35c-ddb1940b28b5)

### classifier
ViT

Resnet50

## Refinement

### optimizing the feature representation for classifier

#### Consistency Learning

**Boundary-Aware Spurious corelations remove ** 



**Which Part of the Teacher Provides a More Informative
Knowledge Source?**

Logits-based:Not suitable for dense prediction tasks, as it lose s spatial information and ignores how the internal representations are formed.

Feature-based:

**Cross-Architecture Feature Alignment Strategies**

Globa

channel

spatial 





#### post-processing
Most of the post-processing techniques are inference-only method,no training is needed.

**CRF**

**SAM-enhanced**
Masks for the image can be generated by sampling a large number of prompts over the image.

The class `SamAutomaticMaskGenerator` implements this capability.It works by sampling single-point prompts in a grid over the image.

There are several tunable parameters in mask generation

**CAM-fusion**

**Multi-scale**

**Sliding window**

**CLip-aided**

**AffinityNet**



### Choosing the layer(s) to extract activations from
CAM can be generated using this repo https://github.com/jacobgil/pytorch-grad-cam
```
ResNet: target_layers = [model.layer4[-1]]
ViT:target_layers = [model.blocks[-1].norm1]

```
# Results
before vs after

![image](https://github.com/user-attachments/assets/8c66ec3e-48f1-4323-8f51-d78060d210bb)

The generated CAMs on our custom dataset.

<img width="427" alt="image" src="https://github.com/user-attachments/assets/b73cc7d3-0c68-4d73-9bfb-1fdf7e765bbe" />
